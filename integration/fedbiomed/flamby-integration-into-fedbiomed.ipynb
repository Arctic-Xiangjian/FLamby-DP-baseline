{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b2ed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25e1352",
   "metadata": {},
   "source": [
    "This notebook highlights practical use cases for the FLamby integration into Fed-BioMed. A few datasets are here tested:\n",
    "1. IXI Tiny\n",
    "2. Heart-Disease\n",
    "3. TCGA-BRCA\n",
    "4. Synthetic\n",
    "5. ISIC\n",
    "\n",
    "For one FLamby dataset (LIDC-IDRI), we noticed conflicts over few packages including Torch, which cannot be easily resolved by changing package versions but need changes in the code (either on FLamby or Fed-BioMed side). This situation shows a certain complexity regarding the interoperability and has to be taken into account for future datasets that will be part of the suite."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375d89cd",
   "metadata": {},
   "source": [
    "### 1. Fed-IXI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2e2065",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from flamby.datasets.fed_ixi import (Baseline as ixi_baseline,\n",
    "                                     BaselineLoss as ixi_baseline_loss,\n",
    "                                     Optimizer as ixi_optimizer,\n",
    "                                     BATCH_SIZE as ixi_batch_size,\n",
    "                                     LR as ixi_lr)\n",
    "\n",
    "class UNetTrainingPlan(TorchTrainingPlan):\n",
    "    # Init of UNetTrainingPlan\n",
    "    def __init__(self, model_args: dict = {}):\n",
    "        super(UNetTrainingPlan, self).__init__(model_args)\n",
    "        \n",
    "        self.model = ixi_baseline() # UNet model\n",
    "        self.loss = ixi_baseline_loss() # Dice loss\n",
    "        \n",
    "        deps = ['from torch.optim import AdamW',\n",
    "               'from flamby.datasets.fed_ixi import (Baseline as ixi_baseline,\\\n",
    "                BaselineLoss as ixi_baseline_loss,\\\n",
    "                Optimizer as ixi_optimizer)',]\n",
    "        self.add_dependency(deps)\n",
    "        \n",
    "        self.optimizer = ixi_optimizer(self.parameters()) # AdamW\n",
    "    \n",
    "    def training_step(self, img, target):\n",
    "        #this function must return the loss to backward it \n",
    "        output = self.model(img)\n",
    "        loss = self.loss(output, target)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dac8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = {\n",
    "    'batch_size': ixi_batch_size,\n",
    "    'lr': ixi_lr,\n",
    "    'epochs': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192e2dc5",
   "metadata": {},
   "source": [
    "*train_transform_flamby* key in **training_args** can optionally be used to perform extra transformations on a flamby dataset.\n",
    "\n",
    "As a reminder, flamby datasets are already internally handling a transformation through their dataloader (this internal transform\n",
    "is the one officially used for the flamby benchmark). Thus, one should check what is already performed on the flamby side before\n",
    "adding transforms through the researcher.\n",
    "\n",
    "*train_transform_flamby* has to be defined as a list containing two elements:\n",
    "- the first is the imports needed to perform the transformation\n",
    "- the second is the Compose object that will be used to input the transform parameter of the flamby dataset federated class\n",
    "\n",
    "Example:\n",
    "```python\n",
    "training_args = {\n",
    "    ...,\n",
    "    'train_transform_flamby':[\"from monai.transforms import (Compose, NormalizeIntensity, Resize,)\",\n",
    "                         \"Compose([Resize((48,60,48)), NormalizeIntensity()])\"]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b915a04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['ixi']\n",
    "num_rounds = 1\n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_class=UNetTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=num_rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc67597",
   "metadata": {},
   "source": [
    "An experiment is a class that orchestrates the training processes that run on different nodes. The experiment has been here initialized with necessary arguments to inform nodes about how to process the training data based on a given model.\n",
    "\n",
    "Let's run the experiment. According to the provided arguments, 1 training round should be completed on the nodes that you created (3 nodes here because there are 3 centers in the case of IXI).\n",
    "Aggregated parameters are saved at the end of the experiment, and their state at every round can be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b05f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b6e5a3",
   "metadata": {},
   "source": [
    "### 2. Fed-Heart-Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd453726",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flamby.datasets.fed_heart_disease import (Baseline as hd_baseline,\n",
    "                                               BaselineLoss as hd_baseline_loss,\n",
    "                                               Optimizer as hd_optimizer,\n",
    "                                               BATCH_SIZE as hd_batch_size,\n",
    "                                               LR as hd_lr)\n",
    "\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from torch.optim import Adam\n",
    "\n",
    "class FedHeartTrainingPlan(TorchTrainingPlan):\n",
    "    def __init__(self, model_args: dict = {}):\n",
    "        super(FedHeartTrainingPlan, self).__init__(model_args)\n",
    "        \n",
    "        self.model = hd_baseline()\n",
    "        self.loss = hd_baseline_loss()\n",
    "        \n",
    "        deps = ['from torch.optim import Adam',\n",
    "                'from flamby.datasets.fed_heart_disease import (Baseline as hd_baseline,\\\n",
    "                BaselineLoss as hd_baseline_loss,\\\n",
    "                Optimizer as hd_optimizer)']\n",
    "        self.add_dependency(deps)\n",
    "        \n",
    "        self.optimizer = hd_optimizer(self.parameters())\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        output = self.model(data)\n",
    "        loss = self.loss(output, target)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e81615",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = {\n",
    "    'batch_size': hd_batch_size,\n",
    "    'lr': hd_lr,\n",
    "    'epochs': 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5992fe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['hd']\n",
    "num_rounds = 1\n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_class=FedHeartTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=num_rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd857d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc611220",
   "metadata": {},
   "source": [
    "### 3. Fed-TCGA-BRCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81850833",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flamby.datasets.fed_tcga_brca import (Baseline as tc_baseline,\n",
    "                                           BaselineLoss as tc_baseline_loss,\n",
    "                                           Optimizer as tc_optimizer,\n",
    "                                           BATCH_SIZE as tc_batch_size,\n",
    "                                           LR as tc_lr)\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from torch.optim import Adam\n",
    "\n",
    "class FedTcgaBrcaTrainingPlan(TorchTrainingPlan):\n",
    "    def __init__(self, model_args: dict = {}):\n",
    "        super(FedTcgaBrcaTrainingPlan, self).__init__(model_args)\n",
    "        \n",
    "        self.model = tc_baseline()\n",
    "        self.loss = tc_baseline_loss()\n",
    "        \n",
    "        deps = ['from torch.optim import Adam',\n",
    "               'from flamby.datasets.fed_tcga_brca import (Baseline as tc_baseline,\\\n",
    "                BaselineLoss as tc_baseline_loss,\\\n",
    "                Optimizer as tc_optimizer)']\n",
    "        self.add_dependency(deps)\n",
    "        \n",
    "        self.optimizer = tc_optimizer(self.parameters())\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        output = self.model(data)\n",
    "        loss = self.loss(output, target)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6b69fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = {\n",
    "    'batch_size': tc_batch_size,\n",
    "    'lr': tc_lr,\n",
    "    'epochs': 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7063002",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['tc']\n",
    "num_rounds = 1\n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_class=FedTcgaBrcaTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=num_rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f9a453",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8d2ca0",
   "metadata": {},
   "source": [
    "### 4. Fed-Synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08101ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flamby.datasets.fed_synthetic import (Baseline as sy_baseline,\n",
    "                                           BaselineLoss as sy_baseline_loss,\n",
    "                                           Optimizer as sy_optimizer,\n",
    "                                           BATCH_SIZE as sy_batch_size,\n",
    "                                           LR as sy_lr)\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from torch.optim import Adam\n",
    "\n",
    "class FedSyntheticTrainingPlan(TorchTrainingPlan):\n",
    "    def __init__(self, model_args: dict = {}):\n",
    "        super(FedSyntheticTrainingPlan, self).__init__(model_args)\n",
    "        \n",
    "        self.model = sy_baseline(model_args.get('input_dim', 10), model_args.get('output_dim', 1)) # specific to synthetic use case\n",
    "        self.loss = sy_baseline_loss()\n",
    "        \n",
    "        deps = ['from torch.optim import Adam',\n",
    "               'from flamby.datasets.fed_synthetic import (Baseline as sy_baseline,\\\n",
    "                BaselineLoss as sy_baseline_loss,\\\n",
    "                Optimizer as sy_optimizer)',]\n",
    "        self.add_dependency(deps)\n",
    "        \n",
    "        self.optimizer = sy_optimizer(self.parameters())\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        #this function must return the loss to backward it \n",
    "        output = self.model(data)\n",
    "        loss = self.loss(output, target)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33826a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = {\n",
    "    'batch_size': sy_batch_size,\n",
    "    'lr': sy_lr,\n",
    "    'epochs': 5,\n",
    "}\n",
    "\n",
    "model_args = {\n",
    "    'input_dim': 10,\n",
    "    'output_dim': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0589792",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['sy']\n",
    "num_rounds = 1\n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 model_class=FedSyntheticTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=num_rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ba6b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a80b2f",
   "metadata": {},
   "source": [
    "### 5. Fed-ISIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dbb09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flamby.datasets.fed_isic2019 import (Baseline as is_baseline,\n",
    "                                          BaselineLoss as is_baseline_loss,\n",
    "                                          Optimizer as is_optimizer,\n",
    "                                          BATCH_SIZE as is_batch_size,\n",
    "                                          LR as is_lr\n",
    "                                         )\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from torch.optim import Adam\n",
    "\n",
    "class FedISICTrainingPlan(TorchTrainingPlan):\n",
    "    def __init__(self, model_args: dict = {}):\n",
    "        super(FedISICTrainingPlan, self).__init__(model_args)\n",
    "        \n",
    "        self.model = is_baseline()\n",
    "        self.loss = is_baseline_loss()\n",
    "        \n",
    "        deps = ['from torch.optim import Adam',\n",
    "               'from flamby.datasets.fed_isic2019 import (Baseline as is_baseline,\\\n",
    "                BaselineLoss as is_baseline_loss,\\\n",
    "                Optimizer as is_optimizer)',]\n",
    "        self.add_dependency(deps)\n",
    "        \n",
    "        self.optimizer = Adam(self.parameters())\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        output = self.model(data)\n",
    "        loss = self.loss(output, target)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af82b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = {\n",
    "    'batch_size': is_batch_size,\n",
    "    'lr': is_lr,\n",
    "    'epochs': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f765ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['is']\n",
    "num_rounds = 1\n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 model_class=FedISICTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=num_rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3b33ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
